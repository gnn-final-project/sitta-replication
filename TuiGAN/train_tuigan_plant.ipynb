{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torchvision import transforms, datasets, models\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from models import *\n",
    "from image_utils import *\n",
    "from train_utils import *\n",
    "from model_utils import *\n",
    "\n",
    "# Set seeds\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# --- Step 1: Train TuiGAN on one healthy/sick pair ---\n",
    "print(\"\\nüöÄ Step 1: Train TuiGAN on single healthy-sick pair\")\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "NUM_ITERS = 4000\n",
    "NUM_SCALES = 5\n",
    "\n",
    "pathA = \"data/healthy2sick_A.jpg\"  # single healthy\n",
    "pathB = \"data/healthy2sick_B.jpg\"  # single sick\n",
    "data_name = \"healthy2sick\"\n",
    "\n",
    "imgA, imgB = read_domains(\"data\", pathA, pathB, resize=True)\n",
    "listA = construct_scale_pyramid(normalize_image_to_tensor(imgA).to(DEVICE)); listA.reverse()\n",
    "listB = construct_scale_pyramid(normalize_image_to_tensor(imgB).to(DEVICE)); listB.reverse()\n",
    "\n",
    "listg_ab, listg_ba, listd_a, listd_b = create_models(num_scale=NUM_SCALES, device=DEVICE)\n",
    "\n",
    "start_time = time.time()\n",
    "train(listA, listB, (listg_ab, listg_ba, listd_a, listd_b))\n",
    "end_time = time.time()\n",
    "\n",
    "save_models(listg_ab, listg_ba, listd_a, listd_b, data_name)\n",
    "print(f\"‚úÖ TuiGAN model trained in {(end_time - start_time):.2f} seconds\")\n",
    "\n",
    "# --- Step 2: Prepare dataset folders ---\n",
    "print(\"\\nüìÅ Step 2: Preparing train/test folders\")\n",
    "\n",
    "src_healthy = \"../data/plant_pathology/healthy\"\n",
    "src_sick = \"../data/plant_pathology/sick\"\n",
    "dst_train_h = \"./data/plant_pathology/train/healthy\"\n",
    "dst_train_s = \"./data/plant_pathology/train/sick\"\n",
    "dst_test_h = \"./data/plant_pathology/test/healthy\"\n",
    "dst_test_s = \"./data/plant_pathology/test/sick\"\n",
    "\n",
    "for f in [dst_train_h, dst_train_s, dst_test_h, dst_test_s]:\n",
    "    os.makedirs(f, exist_ok=True)\n",
    "\n",
    "healthy_imgs = sorted(os.listdir(src_healthy))\n",
    "random.shuffle(healthy_imgs)\n",
    "train_healthy = healthy_imgs[:416]\n",
    "test_healthy = healthy_imgs[416:]\n",
    "\n",
    "for img in train_healthy:\n",
    "    shutil.copy(os.path.join(src_healthy, img), os.path.join(dst_train_h, img))\n",
    "for img in test_healthy:\n",
    "    shutil.copy(os.path.join(src_healthy, img), os.path.join(dst_test_h, img))\n",
    "\n",
    "sick_imgs = sorted(os.listdir(src_sick))\n",
    "test_sick = random.sample(sick_imgs, 81)\n",
    "train_sick_real = list(set(sick_imgs) - set(test_sick))\n",
    "train_sick_sample = random.choice(train_sick_real)\n",
    "shutil.copy(os.path.join(src_sick, train_sick_sample), os.path.join(dst_train_s, train_sick_sample))\n",
    "for img in test_sick:\n",
    "    shutil.copy(os.path.join(src_sick, img), os.path.join(dst_test_s, img))\n",
    "\n",
    "print(\"‚úÖ Dataset folders ready\")\n",
    "\n",
    "# --- Step 3: Generate synthetic sick images using TuiGAN ---\n",
    "print(\"\\nüé® Step 3: Generating fake sick images using TuiGAN\")\n",
    "\n",
    "output_folder = dst_train_s\n",
    "healthy_folder = dst_train_h\n",
    "\n",
    "healthy_list = sorted(os.listdir(healthy_folder))\n",
    "listg_ab, listg_ba, listd_a, listd_b = load_models(\"healthy2sick\", device=DEVICE)\n",
    "\n",
    "for i, fname in enumerate(healthy_list):\n",
    "    pathA = os.path.join(healthy_folder, fname)\n",
    "    imgA = Image.open(pathA).convert(\"RGB\")\n",
    "    listA = construct_scale_pyramid(normalize_image_to_tensor(imgA).to(DEVICE)); listA.reverse()\n",
    "    fake_img, _ = generate_outputs((listA, listB), (listg_ab, listg_ba, listd_a, listd_b), NUM_SCALES - 1)\n",
    "    save_path = os.path.join(output_folder, f\"tuigan_fake_sick_{i+1}.jpg\")\n",
    "    fake_img.save(save_path)\n",
    "\n",
    "print(f\"‚úÖ Generated {len(healthy_list)} synthetic sick images to: {output_folder}\")\n",
    "\n",
    "# --- Step 4: Classification (ResNet18 & VGG16) ---\n",
    "print(\"\\nüß† Step 4: Classification on augmented dataset\")\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((288, 288)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((288, 288)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "train_dataset = datasets.ImageFolder('./data/plant_pathology/train', transform=train_transform)\n",
    "test_dataset = datasets.ImageFolder('./data/plant_pathology/test', transform=test_transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32)\n",
    "\n",
    "def train_and_eval(model_name):\n",
    "    print(f\"üìå Training model: {model_name}\")\n",
    "    if model_name == \"resnet18\":\n",
    "        model = models.resnet18(pretrained=True)\n",
    "        model.fc = nn.Linear(model.fc.in_features, 2)\n",
    "    elif model_name == \"vgg16\":\n",
    "        model = models.vgg16(pretrained=True)\n",
    "        model.classifier[6] = nn.Linear(model.classifier[6].in_features, 2)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported model\")\n",
    "\n",
    "    model = model.to(DEVICE)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "    for epoch in range(10):\n",
    "        model.train()\n",
    "        for imgs, labels in train_loader:\n",
    "            imgs, labels = imgs.to(DEVICE), labels.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(imgs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    # Evaluation\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in test_loader:\n",
    "            imgs, labels = imgs.to(DEVICE), labels.to(DEVICE)\n",
    "            outputs = model(imgs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    acc = 100 * correct / total\n",
    "    print(f\"‚úÖ {model_name} accuracy: {acc:.2f}%\")\n",
    "    return acc\n",
    "\n",
    "resnet_acc = train_and_eval(\"resnet18\")\n",
    "vgg_acc = train_and_eval(\"vgg16\")\n",
    "\n",
    "# --- Step 5: Save results to CSV ---\n",
    "print(\"\\nüíæ Step 5: Saving results to tuigan_43_results.csv\")\n",
    "\n",
    "df = pd.DataFrame([\n",
    "    {\"Model\": \"ResNet18 (TuiGAN)\", \"Accuracy (%)\": round(resnet_acc, 2)},\n",
    "    {\"Model\": \"VGG16 (TuiGAN)\", \"Accuracy (%)\": round(vgg_acc, 2)}\n",
    "])\n",
    "df.to_csv(\"tuigan_plant_results.csv\", index=False)\n",
    "print(\"üìÅ Results saved to tuigan_43_results.csv\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
