{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up [LPIPS] perceptual loss: trunk [vgg], v[0.1], spatial [off]\n",
      "Loading model from: c:\\Users\\Grace\\anaconda3\\envs\\singan\\lib\\site-packages\\lpips\\weights\\v0.1\\vgg.pth\n",
      "\n",
      "📌 Evaluating apple2orange...\n",
      "\n",
      "📌 Evaluating horse2zebra...\n",
      "\n",
      "📌 Evaluating milk2bubblemilk...\n",
      "\n",
      "📌 Evaluating vanilla2chocolate...\n",
      "\n",
      "📊 Evaluation Results (SITTA Table 1 style)\n",
      "           Domain  FID ↓  LPIPS ↓  VGG Loss ↓\n",
      "     apple2orange  15.26   0.1225      8.4556\n",
      "      horse2zebra  12.83   0.2606     20.1463\n",
      "  milk2bubblemilk  73.74   0.3294      8.3797\n",
      "vanilla2chocolate 104.04   0.1406      8.9643\n",
      "          Average  51.47   0.2133     11.4865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Grace\\anaconda3\\envs\\singan\\lib\\site-packages\\ipykernel_launcher.py:93: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import lpips\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "import subprocess\n",
    "import re\n",
    "import shutil\n",
    "import pandas as pd\n",
    "\n",
    "# ✅ 디바이스 설정\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ✅ 모델 로드\n",
    "lpips_model = lpips.LPIPS(net='vgg').eval().to(device)\n",
    "vgg_model = models.vgg19(pretrained=True).features[:8].eval().to(device)\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "# ✅ 이미지 전처리\n",
    "def load_image(image_path):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((288, 288)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    return transform(image).unsqueeze(0).to(device)\n",
    "\n",
    "# ✅ FID 계산 함수\n",
    "def calculate_fid(real_image, generated_image):\n",
    "    real_dir = \"./fid_temp/real\"\n",
    "    gen_dir = \"./fid_temp/generated\"\n",
    "    os.makedirs(real_dir, exist_ok=True)\n",
    "    os.makedirs(gen_dir, exist_ok=True)\n",
    "    for f in os.listdir(real_dir): os.remove(os.path.join(real_dir, f))\n",
    "    for f in os.listdir(gen_dir): os.remove(os.path.join(gen_dir, f))\n",
    "    shutil.copy(real_image, os.path.join(real_dir, \"real.png\"))\n",
    "    shutil.copy(generated_image, os.path.join(gen_dir, \"gen.png\"))\n",
    "\n",
    "    command = f\"python -m pytorch_fid {real_dir} {gen_dir}\"\n",
    "    result = subprocess.run(command, shell=True, capture_output=True, text=True)\n",
    "    output = result.stdout.strip()\n",
    "    match = re.search(r'FID:\\s*([\\d.]+)', output)\n",
    "    if match:\n",
    "        return float(match.group(1))\n",
    "    else:\n",
    "        print(\"⚠️ FID parse failed:\\n\", output)\n",
    "        return None\n",
    "\n",
    "# ✅ LPIPS 계산\n",
    "def calculate_lpips(real_image, generated_image):\n",
    "    img1 = load_image(real_image)\n",
    "    img2 = load_image(generated_image)\n",
    "    with torch.no_grad():\n",
    "        return lpips_model(img1, img2).item()\n",
    "\n",
    "# ✅ VGG perceptual loss 계산\n",
    "def calculate_vgg_loss(real_image, generated_image):\n",
    "    img1 = load_image(real_image)\n",
    "    img2 = load_image(generated_image)\n",
    "    with torch.no_grad():\n",
    "        f1 = vgg_model(img1)\n",
    "        f2 = vgg_model(img2)\n",
    "        return loss_fn(f1, f2).item()\n",
    "\n",
    "# ✅ 도메인 정의\n",
    "domains = [\"apple2orange\", \"horse2zebra\", \"milk2bubblemilk\", \"vanilla2chocolate\"]\n",
    "\n",
    "# ✅ 평가 실행\n",
    "results = []\n",
    "for domain in domains:\n",
    "    print(f\"\\n📌 Evaluating {domain}...\")\n",
    "    real_img = f\"../../data/processed/singan/{domain}_B.jpg\"\n",
    "    gen_img = f\"./results/{domain}/s11/s9_sampled.png\"\n",
    "\n",
    "    fid = calculate_fid(real_img, gen_img)\n",
    "    lpips_score = calculate_lpips(real_img, gen_img)\n",
    "    vgg_loss = calculate_vgg_loss(real_img, gen_img)\n",
    "\n",
    "    results.append({\n",
    "        \"Domain\": domain,\n",
    "        \"FID ↓\": round(fid, 2) if fid is not None else \"N/A\",\n",
    "        \"LPIPS ↓\": round(lpips_score, 4),\n",
    "        \"VGG Loss ↓\": round(vgg_loss, 4)\n",
    "    })\n",
    "\n",
    "# ✅ 평균 추가\n",
    "df = pd.DataFrame(results)\n",
    "avg_row = {\n",
    "    \"Domain\": \"Average\",\n",
    "    \"FID ↓\": round(df[\"FID ↓\"].replace(\"N/A\", pd.NA).dropna().astype(float).mean(), 2) if \"N/A\" not in df[\"FID ↓\"].values else \"N/A\",\n",
    "    \"LPIPS ↓\": round(df[\"LPIPS ↓\"].mean(), 4),\n",
    "    \"VGG Loss ↓\": round(df[\"VGG Loss ↓\"].mean(), 4)\n",
    "}\n",
    "df.loc[len(df)] = avg_row\n",
    "\n",
    "# ✅ 결과 출력\n",
    "print(\"\\n📊 Evaluation Results (SITTA Table 1 style)\")\n",
    "print(df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "singan",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
