import torch
import lpips
import torchvision.models as models
import torchvision.transforms as transforms
from PIL import Image
import os
import subprocess
import re
import shutil
import pandas as pd

# âœ… ë””ë°”ì´ìŠ¤ ì„¤ì •
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# âœ… ëª¨ë¸ ë¡œë“œ
lpips_model = lpips.LPIPS(net='vgg').eval().to(device)
vgg_model = models.vgg19(pretrained=True).features[:8].eval().to(device)
loss_fn = torch.nn.MSELoss()

# âœ… ì´ë¯¸ì§€ ì „ì²˜ë¦¬
def load_image(image_path):
    transform = transforms.Compose([
        transforms.Resize((288, 288)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406],
                             std=[0.229, 0.224, 0.225])
    ])
    image = Image.open(image_path).convert("RGB")
    return transform(image).unsqueeze(0).to(device)

# âœ… FID ê³„ì‚° í•¨ìˆ˜
def calculate_fid(real_image, generated_image):
    real_dir = "./fid_temp/real"
    gen_dir = "./fid_temp/generated"
    os.makedirs(real_dir, exist_ok=True)
    os.makedirs(gen_dir, exist_ok=True)
    for f in os.listdir(real_dir): os.remove(os.path.join(real_dir, f))
    for f in os.listdir(gen_dir): os.remove(os.path.join(gen_dir, f))
    shutil.copy(real_image, os.path.join(real_dir, "real.png"))
    shutil.copy(generated_image, os.path.join(gen_dir, "gen.png"))

    command = f"python -m pytorch_fid {real_dir} {gen_dir}"
    result = subprocess.run(command, shell=True, capture_output=True, text=True)
    output = result.stdout.strip()
    match = re.search(r'FID:\s*([\d.]+)', output)
    if match:
        return float(match.group(1))
    else:
        print("âš ï¸ FID parse failed:\n", output)
        return None

# âœ… LPIPS ê³„ì‚°
def calculate_lpips(real_image, generated_image):
    img1 = load_image(real_image)
    img2 = load_image(generated_image)
    with torch.no_grad():
        return lpips_model(img1, img2).item()

# âœ… VGG perceptual loss ê³„ì‚°
def calculate_vgg_loss(real_image, generated_image):
    img1 = load_image(real_image)
    img2 = load_image(generated_image)
    with torch.no_grad():
        f1 = vgg_model(img1)
        f2 = vgg_model(img2)
        return loss_fn(f1, f2).item()

# âœ… ë„ë©”ì¸ ì •ì˜
domains = ["apple2orange", "horse2zebra", "milk2bubblemilk", "vanilla2chocolate"]

# âœ… í‰ê°€ ì‹¤í–‰
results = []
for domain in domains:
    print(f"\nğŸ“Œ Evaluating {domain}...")
    real_img = f"../../data/processed/singan/{domain}_B.jpg"
    gen_img = f"./results/{domain}/s11/s9_sampled.png"

    fid = calculate_fid(real_img, gen_img)
    lpips_score = calculate_lpips(real_img, gen_img)
    vgg_loss = calculate_vgg_loss(real_img, gen_img)

    results.append({
        "Domain": domain,
        "FID â†“": round(fid, 2) if fid is not None else "N/A",
        "LPIPS â†“": round(lpips_score, 4),
        "VGG Loss â†“": round(vgg_loss, 4)
    })

# âœ… í‰ê·  ì¶”ê°€
df = pd.DataFrame(results)
avg_row = {
    "Domain": "Average",
    "FID â†“": round(df["FID â†“"].replace("N/A", pd.NA).dropna().astype(float).mean(), 2) if "N/A" not in df["FID â†“"].values else "N/A",
    "LPIPS â†“": round(df["LPIPS â†“"].mean(), 4),
    "VGG Loss â†“": round(df["VGG Loss â†“"].mean(), 4)
}
df.loc[len(df)] = avg_row

# âœ… ê²°ê³¼ ì¶œë ¥
print("\nğŸ“Š Evaluation Results (SITTA Table 1 style)")
print(df.to_string(index=False))